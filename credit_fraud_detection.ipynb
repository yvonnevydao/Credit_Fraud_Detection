{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45047765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "# Set Random Seed\n",
    "seed = np.random.seed(123)\n",
    "sns.set_theme(context = 'paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e5cca",
   "metadata": {},
   "source": [
    "# <span style=\"color: blue;\"> Credit Card Fraud Detection</span>\n",
    "\n",
    "**Objective**\n",
    "\n",
    "**i. Dataset**\n",
    "\n",
    "**Project Pipeline**\n",
    "- Import and understand the fraud data\n",
    "- See if the data has any shortcomings like missing data or imbalance, and then fix them\n",
    "- Train models on the data using K-Fold Cross Validation\n",
    "- Evaluate the performance of the models using various metrics\n",
    "- Rank the model based on their performance and visualize the results\n",
    "    \n",
    "**ii. Pre-processing**\n",
    "\n",
    "**iii. Training models**\n",
    "\n",
    "**iv. Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0c0b1",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">Objective\n",
    "### Credit Card Fraud \n",
    "- Credit card fraud is the unauthorized use of a credit card to make purchases or withdraw funds.\n",
    "### Source \n",
    "- The dataset contains transactions made by credit cards in September 2013 by European cardholders, and also available in Kaggle.\n",
    "### Objective\n",
    "- to detect fraudulent credit card transactions or not based on synthetic features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112fb37d",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">i. Dataset\n",
    "- It contains only numerical input variables which are the result of a PCA transformation. \n",
    "- There are a total of 31 features in the dataset.\n",
    "    - `V1, V2, … V28` are the principal components obtained with PCA\n",
    "    - `Time` contains the seconds elapsed between each transaction and the first transaction in the dataset.\n",
    "    - `Amount` is the transaction Amount\n",
    "    - Target: `Class` 1 in case of fraud and 0 otherwise.\n",
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250d69b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (284807, 31)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "display(df.head())\n",
    "print('Shape of the dataset:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574f0114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd1af6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0789f8",
   "metadata": {},
   "source": [
    "### Checking for NaN presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e4c46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876e8089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking for NaN presence\n",
    "df.isna().sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f34891",
   "metadata": {},
   "source": [
    "### Class Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f737851b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = df['Class'].value_counts()\n",
    "display(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff6dd5",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">ii. Pre-processing\n",
    "### <span style=\"color: blue;\">Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2e5182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a030626",
   "metadata": {},
   "source": [
    "There are 1081 duplicated rows in the dataset. Duplicate rows can skew the analysis and the results of the model trainning, as they can introduce bias and potentially lead to overfitting.\n",
    "Removing duplicates is generally a good practice in data preprocessing, especially in a sensitive task like fraud detection where accuracy is critical. So, I am gonna remove that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32acbf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing duplicates: 283726\n"
     ]
    }
   ],
   "source": [
    "## Remove the Duplicate Rows\n",
    "df_new = df.drop_duplicates()\n",
    "# Verify the number of rows after removing duplicates\n",
    "print('Number of rows after removing duplicates:',df_new.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7dda30",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue;\">Class Distribution (after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c01b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    283253\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = df_new['Class'].value_counts()\n",
    "display(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace8756",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue;\">Bar Plot showing the Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882646c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=class_counts.index, y=class_counts.values);\n",
    "plt.title('Class Distribution');\n",
    "plt.xlabel('Class');\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebfaba",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue;\"> Pie Chart to show the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b473cc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(class_counts, labels=class_counts.index, autopct='%1.2f%%');\n",
    "plt.title('Class Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee56660",
   "metadata": {},
   "source": [
    "As we can see, the dataset is very imbalanced as most of the transaction are **Non-Fraud**. Use this dataset for predictive models might cause a lot of errors because the models will tend to overfit since it gonna assume the most transactions are Non-Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf5c77",
   "metadata": {},
   "source": [
    "# <span style=\"color: red;\">---------------------------------------\n",
    "# <span style=\"color: red;\">---------------------------------------\n",
    "# <span style=\"color: red;\">---------------------------------------   \n",
    "### Plotting the distribution of 'Class' for each variable\n",
    "- It helps us to understand whether the skewness in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b02978f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Accumulating all the column names under one variable\\ncols = list(X.columns.values)\\n\\n# Plot the histogram of a variable from the dataset to see the skewness\\nnormal_records = df2.Class == 0\\nfraud_records = df2.Class == 1\\n\\nplt.figure(figsize=(20,60))\\nfor n, col in enumerate(cols):\\n    plt.subplot(10,3,n+1)\\n    sns.histplot(X[col][normal_records], color='green', kde=True, stat='density', label='Normal')\\n    sns.histplot(X[col][fraud_records], color='red', kde=True, stat='density', label='Fraud')\\n    plt.title(col, fontsize=17)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Accumulating all the column names under one variable\n",
    "cols = list(X.columns.values)\n",
    "\n",
    "# Plot the histogram of a variable from the dataset to see the skewness\n",
    "normal_records = df2.Class == 0\n",
    "fraud_records = df2.Class == 1\n",
    "\n",
    "plt.figure(figsize=(20,60))\n",
    "for n, col in enumerate(cols):\n",
    "    plt.subplot(10,3,n+1)\n",
    "    sns.histplot(X[col][normal_records], color='green', kde=True, stat='density', label='Normal')\n",
    "    sns.histplot(X[col][fraud_records], color='red', kde=True, stat='density', label='Fraud')\n",
    "    plt.title(col, fontsize=17)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe0fc3f",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Confusion Matrix\n",
    "- Classification Report: Precision, Recall, F1 Score, etc.\n",
    "- Area Under the Curve (AUC) of Receiver Operating Characteristic (ROC)\n",
    "    - the higher AUC, the better the performanace of the model at distinguishing between the positive and negative classes.\n",
    "\n",
    "https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b71b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store results\n",
    "df_Results = pd.DataFrame(columns=['Methodology', 'Model', 'roc_value', 'threshold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38bc2f3",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8805af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Create a common function to plot 'Confusion Matrix'\n",
    "def Plot_Confusion_Matrix(y_test, pred_test):\n",
    "    cm = confusion_matrix(y_test, pred_test)\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent)\n",
    "    categoryNames = ['Non-Fraudalent', 'Fraudalent']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ticks = np.arange(len(categoryNames))\n",
    "    plt.xticks(ticks, categoryNames, rotation=45)\n",
    "    plt.yticks(ticks, categoryNames)\n",
    "    s = [['TN', 'FP'], ['FN', 'TP']]\n",
    "    # print the value\n",
    "    for i in range(2): \n",
    "        for j in range(2):\n",
    "            plt.text(j,o, str(s[i][j])+' = '+str(cm[i][j]),frontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37782af2",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression\n",
    "- Create a common function to fit and predict on a Logistic Regression model for both: `L1` and `L2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0121ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def LogisticModels(df_Results, Methodology, X_train, y_train, X_test, y_test):\n",
    "    # K-Fold cross-validator\n",
    "    num_C = list(np.power(10.0, np.arange(-10,10)))\n",
    "    cv_num = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    ## L2\n",
    "    searchCV_L2 = linear_model.LogisticRegressionCV(\n",
    "            Cs= num_C,\n",
    "            penalty= 'l2',\n",
    "            scoring= 'roc_auc',\n",
    "            cv= cv_num,\n",
    "            random_state=seed,\n",
    "            max_iter=10000,\n",
    "            fit_intercept=True,\n",
    "            solver='newton-cg',\n",
    "            tol=10)\n",
    "    ## L1\n",
    "    searchCV_L1 = linear_model.LogisticRegressionCV(\n",
    "            Cs= num_C,\n",
    "            penalty= 'l1',\n",
    "            scoring= 'roc_auc',\n",
    "            cv= cv_num,\n",
    "            random_state=seed,\n",
    "            max_iter=10000,\n",
    "            fit_intercept=True,\n",
    "            solver='newton-cg',\n",
    "            tol=10)\n",
    "    # Fit the models\n",
    "    searchCV_L2.fit(X_train, y_train) # L2\n",
    "    searchCV_L1.fit(X_train, y_train) # L1\n",
    "    \n",
    "    # Max AUC_ROC\n",
    "    print('Max AUC_ROC for L2:', searchCV_L2.scores_[1].mean(axis=0).max())\n",
    "    print('Max AUC_ROC for L1:', searchCV_L1.scores_[1].mean(axis=0).max())\n",
    "    \n",
    "    # Parameters for L2 Regularization\n",
    "    print('\\nParameters for L2 Regularization:')\n",
    "    print(searchCV_L2.coef_)\n",
    "    print(searchCV_L2.intercept_)\n",
    "    print(searchCV_L2.scores_)\n",
    "    # Parameters for L1 Regularization\n",
    "    print('\\nParameters for L1 Regularization:')\n",
    "    print(searchCV_L1.coef_)\n",
    "    print(searchCV_L1.intercept_)\n",
    "    print(searchCV_L1.scores_)\n",
    "    \n",
    "    # Predicted values\n",
    "    y_pred_L2 = searchCV_L2.predict(X_test)\n",
    "    y_pred_L1 = searchCV_L1.predict(X_test)\n",
    "    \n",
    "    # Predicted Probabilities\n",
    "    y_pred_prob_L2 = searchCV_L2.predict_proba(X_test)[:,1]\n",
    "    y_pred_prob_L1 = searchCV_L1.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Accuracy of L2 and L1 models\n",
    "    Accuracy_L2 = metrics.accuracy_score(y_pred=y_pred_L2, y_true=y_test)\n",
    "    ## L2\n",
    "    print('\\nAccuracy of Logistic model with L2 Regularization: {0}'.format(Accuracy_L2))\n",
    "    print('Confusion Matrix') \n",
    "    Plot_Confusion_Matrix(y_test, y_pred_L2)\n",
    "    \n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test, y_pred_L2))\n",
    "    \n",
    "    ## L1\n",
    "    Accuracy_L1 = metrics.accuracy_score(y_pred=y_pred_L1, y_true=y_test)\n",
    "    print('\\nAccuracy of Logistic model with L1 Regularization: {0}'.format(Accuracy_L1))\n",
    "    print('Confusion Matrix') \n",
    "    Plot_Confusion_Matrix(y_test, y_pred_L1)\n",
    "    \n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test, y_pred_L1))\n",
    "    \n",
    "    # L2 ROC Value -------------------------------------------\n",
    "    L2_ROC_value = roc_auc_score(y_test, y_pred_prob_L2)\n",
    "    print(f'\\nL2 ROC value: {L2_ROC_value}')\n",
    "    FPR, TPR, thresholds = metrics.roc_curve(y_test, y_pred_prob_L2)\n",
    "    threshold = thresholds[np.argmax(TPR-FPR)]\n",
    "    print(f'L2 threshold: {threshold}')\n",
    "    \n",
    "    ROC_AUC = metrics.auc(FPR, TPR)\n",
    "    print(f'ROC for the test dataset {ROC_AUC}')\n",
    "    plt.plot(FPR, TPR, label='Test, AUC='+str(ROC_AUC))\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    \n",
    "    df_Results = df_Results.append(pd.DataFrame({'Methodology':Methodology,\n",
    "                                                'Model':'Logistic Regression with L2 Regularization',\n",
    "                                                'Accuracy':Accuracy_L2,\n",
    "                                                'roc_value':L2_ROC_value,\n",
    "                                                'threshold':threshold}))\n",
    "    \n",
    "    # L1 ROC Value ---------------------------------------------\n",
    "    L1_ROC_value = roc_auc_score(y_test, y_pred_prob_L1)\n",
    "    print(f'\\nL1 ROC value: {L1_ROC_value}')\n",
    "    FPR, TPR, thresholds = metrics.roc_curve(y_test, y_pred_prob_L1)\n",
    "    threshold = thresholds[np.argmax(TPR-FPR)]\n",
    "    print(f'L1 threshold: {threshold}')\n",
    "    \n",
    "    ROC_AUC = metrics.auc(FPR, TPR)\n",
    "    print(f'ROC for the test dataset {ROC_AUC}')\n",
    "    plt.plot(FPR, TPR, label='Test, AUC='+str(ROC_AUC))\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    \n",
    "    df_Results = df_Results.append(pd.DataFrame({'Methodology':Methodology,\n",
    "                                                'Model':'Logistic Regression with L1 Regularization',\n",
    "                                                'Accuracy':Accuracy_L1,\n",
    "                                                'roc_value':L1_ROC_value,\n",
    "                                                'threshold':threshold}))\n",
    "    return df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0b616",
   "metadata": {},
   "source": [
    "### 2. K-Nearest Neighbour (KNN)\n",
    "- The number of nearest neighbours to a new unknown variable that has to be predicted or classified is denoted by the symbol 'K'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68bd4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def KNN_Models(df_Results, Methodology, X_train, y_train, X_test, y_test):\n",
    "    # create KNN model and fit the model with training dataset\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=16)\n",
    "    knn.fit(X_train, y_test)\n",
    "    score = knn.score(X_test, y_test)\n",
    "    print('Model score:')\n",
    "    print(score)\n",
    "    \n",
    "    # Accuracy ---------------------------------------\n",
    "    y_pred = knn.predict(X_test)\n",
    "    KNN_Accuracy = metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    print('Confusion Matrix')\n",
    "    Plot_Confusion_Matrix(y_test, y_pred)\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    knn_probs = knn.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Calculate ROC AUC ---------------------------------\n",
    "    KNN_roc_value = roc_auc_score(y_test, knn_probs)\n",
    "    print('KNN roc_value:', KNN_roc_value)\n",
    "    FPR, TPR, thresholds = metrics.roc_curve(y_test, knn_probs)\n",
    "    threshold = thresholds[np.argmax(TPR - FPR)]\n",
    "    print('KNN threshold:', threshold)\n",
    "    \n",
    "    roc_auc = metrics.auc(FPR, TPR)\n",
    "    print('ROC for the test dataset:','{:.1%}'.format(roc_auc))\n",
    "    plt.plot(FPR, TPR, label='Test, AUC='+str(roc_auc))\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    \n",
    "    df_Results = df_Results.append(pd.DataFrame({'Methodology':Methodology,\n",
    "                                                'Model':'KNN',\n",
    "                                                'Accuracy':score,\n",
    "                                                'roc_value':KNN_roc_value,\n",
    "                                                'threshold':threshold}))\n",
    "    return df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8b6df",
   "metadata": {},
   "source": [
    "### 3. Decision Tree Classifier\n",
    "- Gini\n",
    "- Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96a7f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def TreeModels(df_Results, Methodology, X_train, y_train, X_test, y_test):\n",
    "    # Evaluate Decision Tree with 'gini' and 'entropy'\n",
    "    criteria = ['gini', 'entropy']\n",
    "    scores = {}\n",
    "    \n",
    "    for c in criteria:\n",
    "        dt = DecisionTreeClassifier(criterion=c, random_state=seed)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred = dt.predict(X_test)\n",
    "        test_score = dt.score(X_test, y_test)\n",
    "        tree_preds = dt.predict_proba(X_test)[:,1]\n",
    "        tree_ROC_value = roc_auc_score(y_test, tree_preds)\n",
    "        scores = test_score\n",
    "        print(c + 'score: {0}' .format(test_score))\n",
    "        ## Confusion Matrix\n",
    "        print('\\nConfusion Matrix:')\n",
    "        Plot_Confusion_Matrix(y_test, y_pred)\n",
    "        ## Classification Report\n",
    "        print('\\nClassification Report:')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(c + 'tree_ROC_value: {0}' .format(tree_ROC_value))\n",
    "        FPR, TPR, thresholds = metrics.roc_curve(y_test, tree_preds)\n",
    "        threshold = thresholds[np.argmax(TPR-FPR)]\n",
    "        print('Tree threshold: {0}' .format(threshold))\n",
    "        roc_auc = metrics.auc(FPR, TPR)\n",
    "        print('ROC for the test dataset', '{:.1%}'.format(roc_auc))\n",
    "        plt.plot(FPR, TPR, label='Test, auc='+str(roc_auc))\n",
    "        plt.legend(loc=4)\n",
    "        plt.show()\n",
    "        \n",
    "        df_Results = df_Results.append(pd.DataFrame({'Methodology':Methodology,\n",
    "                                                'Model':'Tree Model with {0} criteria'.format(c),\n",
    "                                                'Accuracy':test_score,\n",
    "                                                'roc_value':tree_ROC_value,\n",
    "                                                'threshold':threshold}))\n",
    "        return df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589397d",
   "metadata": {},
   "source": [
    "### 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c7225e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def RandomForest_Models(df_Results, Methodology, X_train, y_train, X_test, y_test):\n",
    "    # Evaluate Random Forest models \n",
    "    # Create the model with 100 trees\n",
    "    RF_model = RandomForestClassifier(n_estimators=100,\n",
    "                                     bootstrap=True,\n",
    "                                     max_features='sqrt',\n",
    "                                     random_state=seed)\n",
    "    # Fit on training data\n",
    "    RF_model.fit(X_train, y_train)\n",
    "    RF_test_score = RF_model.score(X_test, y_test) \n",
    "    RF_model.predict(X_test)\n",
    "    \n",
    "    print('Model Accuracy :', RF_test_score)\n",
    "    \n",
    "    # Actual class prediction\n",
    "    rf_predictions = RF_model.predict(X_test)\n",
    "    # Confusion Matrix\n",
    "    print('Confusion Matrix')\n",
    "    Plot_Confusion_Matrix(y_test, rf_predictions)\n",
    "    # Classification Report\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test, rf_predictions))\n",
    "    \n",
    "    # Probabilities for each class\n",
    "    rf_probs = RF_model.predict_proba(X_test)[:,1]\n",
    "    # Calculate ROC AUC\n",
    "    ROC_value = roc_auc_score(y_test, rf_probs)\n",
    "    \n",
    "    print(f'Random Forest roc_value: {ROC_value}')\n",
    "    FPR, TPR, thresholds = metrics.roc_curve(y_test, rf_probs)\n",
    "    threshold = thresholds[np.argmax(TPR-FPR)]\n",
    "    print(f'Random Forest threshold: {threshold}')\n",
    "    roc_auc = metrics.auc(FPR, TPR)\n",
    "    print('ROC for the test dataset', '{:.1%}'.format(roc_auc))\n",
    "    plt.plot(FPR, TPR, label='Test, auc='+str(roc_auc))\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "        \n",
    "    df_Results = df_Results.append(pd.DataFrame({'Methodology':Methodology,\n",
    "                                                'Model':'Random Forest',\n",
    "                                                'Accuracy':RF_test_score,\n",
    "                                                'roc_value':ROC_value,\n",
    "                                                'threshold':threshold}, \n",
    "                                                index=[0]), ignore_index=True)\n",
    "    return df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7704a53",
   "metadata": {},
   "source": [
    "### 5. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38ea9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def XGBoost(df_Results, Methodology, X_train, y_train, X_test, y_test):\n",
    "    # Evaluate XGBoost model\n",
    "    XGBoost_model = GradientBoostingClassifier(random_state=seed)\n",
    "    XGBoost_model.fit(X_train, y_train)\n",
    "    y_pred = XGBoost_model.predict(X_test)\n",
    "    # Model Accuracy\n",
    "    XGB_test_score = XGBoost_model.score(X_test, y_test)\n",
    "    print('Model Accuracy: {0}'.format(XGB_test_score))\n",
    "    # Confusion Matrix\n",
    "    print('Confusion Matrix')\n",
    "    Plot_Confusion_Matrix(y_test, y_pred)\n",
    "    # Classification Report\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Probabilities for each class\n",
    "    XGB_probs = XGBoost_model.predict_proba(X_test)[:, 1]\n",
    "    # Calculate ROC AUC\n",
    "    XGB_roc_value = roc_auc_score(y_test, XGB_probs)\n",
    "    print('XGBoosting roc_value: {0}'.format(XGB_roc_value))\n",
    "    FPR, TPR, thresholds = metrics.roc_curve(y_test, XGB_probs)\n",
    "    threshold = thresholds[np.argmax(TPR-FPR)]\n",
    "    print('XGBoost threshold: {0}'.format(threshold))\n",
    "    roc_auc = metrics.auc(FPR, TPR)\n",
    "    print('ROC for the test dataset', '{:.1%}'.format(roc_auc))\n",
    "    plt.plot(FPR, TPR, label='Test, auc='+str(roc_auc))\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "        \n",
    "    df_Results = df_Results.append(pd.DataFrame({'Methodology':Methodology,\n",
    "                                                'Model':'XGBoost',\n",
    "                                                'Accuracy':XGB_test_score,\n",
    "                                                'roc_value':XGB_roc_value,\n",
    "                                                'threshold':threshold}, \n",
    "                                                index=[0]), ignore_index=True)\n",
    "    return df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03007f81",
   "metadata": {},
   "source": [
    "### 6. Support Vector Machine (SVM)\n",
    "- Plot each data item as a point in n-dimensional space (where n is a number of features we have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiates the two classes very well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce191f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def SVM_Models(df_Results, Methodology, X_train, y_train, X_test, y_test):\n",
    "    # Evaluate SVM model with sigmoid kernel model\n",
    "    clf = SVC(kernel='sigmoid', random_state=deed)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_SVM = clf.predict(X_test)\n",
    "    # Accuracy score\n",
    "    SVM_Score = accuracy_score(y_test, y_pred_SVM)\n",
    "    print('Accuracy Score: {0}'.format(SVM_Score))\n",
    "    # Confusion Matrix\n",
    "    print('Confusion Matrix')\n",
    "    Plot_Confusion_Matrix(y_test, y_pred_SVM)\n",
    "    # Classification Report\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test, y_pred_SVM))\n",
    "    \n",
    "    # Run classifier\n",
    "    classifier = SVC(kernel='sigmoid', probability=True)\n",
    "    SVM_probs = classifier.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Calculate roc auc\n",
    "    roc_value = roc_auc_score(y_test, SVM_probs)\n",
    "    \n",
    "    print('SVM roc_value: {0}'.format(roc_value))\n",
    "    FPR, TPR, thresholds = metrics.roc_curve(y_test, SVM_probs)\n",
    "    threshold = thresholds[np.argmax(TPR-FPR)]\n",
    "    print('SVM threshold: {0}'.format(threshold))\n",
    "    roc_auc = metrics.auc(FPR, TPR)\n",
    "    print('ROC for the test dataset', '{:.1%}'.format(roc_auc))\n",
    "    plt.plot(FPR, TPR, label='Test, auc='+str(roc_auc))\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "        \n",
    "    df_Results = df_Results.append(pd.DataFrame({'Methodology':Methodology,\n",
    "                                                'Model':'SVM',\n",
    "                                                'Accuracy':SVM_Score,\n",
    "                                                'roc_value':roc_value,\n",
    "                                                'threshold':threshold}, \n",
    "                                                index=[0]), ignore_index=True)\n",
    "    return df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f636d",
   "metadata": {},
   "source": [
    "Build different models on the imbalanced dataset and see the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96609fd",
   "metadata": {},
   "source": [
    "## Perform Cross Validation with `RepeatedKFold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6bad292",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m rKF \u001b[38;5;241m=\u001b[39m RepeatedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      4\u001b[0m                    n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      5\u001b[0m                    random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# X is the feature set and y is the target\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m rKF\u001b[38;5;241m.\u001b[39msplit(X,y):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAIN:\u001b[39m\u001b[38;5;124m'\u001b[39m, train_index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEST:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_index)\n\u001b[1;32m      9\u001b[0m     X_train_cv, X_test_cv \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index], X\u001b[38;5;241m.\u001b[39miloc[test_index]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Perform RepeatedKFold and check the results\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "rKF = RepeatedKFold(n_splits=5,\n",
    "                   n_repeats=10,\n",
    "                   random_state=None)\n",
    "# X is the feature set and y is the target\n",
    "for train_index, test_index in rKF.split(X,y):\n",
    "    print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "    X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61de2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "## Run Logistic Regression with L1 and L2 Regularisation\n",
    "print('Logistic Regression with L1 and L2 Regularisation')\n",
    "start_time = time.time()\n",
    "df_Results = LogisticModels(df_Results, 'RepeatedKFold Cross Validation',\n",
    "                           X_train_cv, y_train_cv, X_test_cv, y_test_cv)\n",
    "print('Time Taken by Model:--- %s seconds ---'%(time.time() - start_time))\n",
    "print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef833c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f77185a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
